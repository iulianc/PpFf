
\chapter{Logiciels et bibliothèques de traitement de flux de donn\'ees~: \TT{Spark}, \TT{Java}, \TT{FastFlow} et autres}
\label{outils_connus}
\label{outils_connus.chap}


La programmation parall\`ele devient de plus en plus une n\'ecessit\'e avec l'apparition des architectures multicœurs. Jusqu'\`a il y a quelques ann\'ees, une des principales fa\c{c}ons d'ex\'ecuter un programme plus rapidement \'etait gr\^ace \`a l'augmentation de la vitesse d'horloge du processeur. De nos jours, la vitesse d'horloge a atteint ses limites et les performances d'un programme ne peuvent souvent \^etre am\'elior\'ees que si on l'ex\'ecute en parall\`ele. 

Il existe de nombreuses approches et de nombreux langages de programmation parall\`ele.
%
Le paradigme de programmation parall\`ele \emph{par flux de donn\'ees} offre une approche prometteuse pour la programmation de syst\`emes multicœurs. C'est cette approche que nous allons bri\`evement d\'ecrire avant de pr\'esenter trois langages existants qui mettent en \oe{}uvre cette approche.

\section{Parall\'elisme de flux de donn\'ees}


Un \emph{flux de donn\'ees} est une suite potentiellement infinie de donn\'ees, g\'en\'er\'ees par diff\'erentes sources, qui peut \^etre trait\'ee de fa\c{c}on incr\'ementale par des processus interconnect\'es. Typiquement, le traitement des donn\'ees d'un flux s'effectue \`a l'aide d'une s\'equence d'op\'erations --- un \emph{pipeline} d'op\'erations. Les op\'erations typiques de traitement de flux des donn\'ees comprennent notamment le tri, le filtrage,  la transformation, l'accumulation. Lorsque ces op\'erations sont ex\'ecut\'ees par diff\'erents \emph{threads}, on parle alors de \emph{parall\'elisme de flux de donn\'ees}. Le traitement complet d'une suite d'\'el\'ements de donn\'ee se fait, conceptuellement, en faisant migrer d'une op\'eration \`a une autre les divers \'el\'ements, dans l'ordre dans lequel ils sont \'emis par les sources des donn\'ees.
%
Un \'el\'ement de donn\'ee doit donc parcourir plusieurs \'etapes de traitement, mais divers \'el\'ements peuvent \^etre en cours de traitement \`a un instant donn\'e, d'o\`u le parall\'elisme.

Un tel traitement en pipeline peut aussi \^etre utilis\'e pour des collections \emph{finies} de donn\'ees. Connu comme le mod\`ele de traitement par lots (\emph{batch processing}), le traitement de telles collections peut se faire en traitant chaque collection comme un tout, ou se faire \'el\'ement par \'el\'ement \`a travers un pipeline d'op\'erations et avec du parall\'elisme de flux de donn\'ees.


Il existe de nombreux syst\`emes de traitement de flux de donn\'ees. La conception, le mod\`ele et l'architecture de ces syst\`emes diff\`erent, de sorte qu'ils poss\`edent des fonctionnalit\'es et des performances diff\'erentes. Ce chapitre pr\'esente un aper\c{c}u de trois syst\`emes de traitement de flux de donn\'ees~: \TT{Apache Spark} (Sect.~\ref{spark.sect}), les \TT{Stream}s de \TT{Java}~8 (Sect.~\ref{java8.sect}) et \TT{FastFlow} (Sect.~\ref{fastflow.sect}).  Ce sont trois parmi les nombreux syst\`emes actuellement disponibles, que nous avons choisi de pr\'esenter parce qu'ils ont servi d'inspiration et de base au syst\`eme que nous avons d\'evelopp\'e, \ppff, que nous pr\'esenterons aux chapitres~\ref{description.chap} et~\ref{implementation.chap}.


\section{Apache Spark}

\label{spark.sect}


\TT{Apache Spark}~\citep{apachSpark} est un engin de traitement de flux de donn\'ees dot\'e d'une API expressive qui permet aux d\'eveloppeurs d'ex\'ecuter efficacement plusieurs op\'erations sur une collection de donn\'ees. \TT{Spark} est un outil de traitement par lots, mais qui a aussi des capacit\'es de traitement de flux incr\'emental de donn\'ees. Il se concentre principalement sur l'acc\'el\'eration du traitement des donn\'ees en gardant en m\'emoire les donn\'ees de travail, ce qui permet notamment l'acc\'el\'eration du traitement des algorithmes it\'eratifs.

Alors que le traitement en m\'emoire contribue consid\'erablement \`a obtenir de hautes performances, Spark est \'egalement rapide avec le traitement de donn\'ees sur disques en raison de l'optimisation qui peut \^etre r\'ealis\'ee en analysant l'ensemble complet des t\^aches \`a l'avance. Ceci peut \^etre r\'ealis\'e en cr\'eant des graphes acycliques dirig\'es (DAG) qui repr\'esentent toutes les op\'erations qui doivent \^etre ex\'ecut\'ees, les donn\'ees \`a \^etre utilis\'ees, ainsi que les relations entre elles. \`A l'aide de ce graphe, le syst\`eme d'ex\'ecution a la capacit\'e de planifier et d'ordonnancer le travail de fa\c{c}on efficace.

\TT{Spark} utilise un mod\`ele appel\'e \emph{Resilient Distributed Datasets} (\TT{RDD})~\citep{Salloum2016} pour repr\'esenter les collections de donn\'ees, mod\`ele qui g\`ere efficacement la persistence lorsque les donn\'ees ne peuvent pas toutes \^etre trait\'ees en m\'emoire ou lorsqu'elles doivent \^etre pr\'eserv\'ees pour \'eviter des recalculs. De plus, \TT{Spark} impl\'emente le mod\`ele \emph{Discretized Streams}~\citep{zaharia2013discretized} pour le traitement de flux incr\'emental de donn\'ees.
%
Nous expliquons ces deux mod\`eles dans les sous-sections qui suivent.


\subsection{\emph{Resilient Distributed Dataset} (\TT{RDD})}

Un \TT{RDD} est une abstraction de donn\'ees en m\'emoire qui \'evite la r\'eplication de donn\'ees et minimise les acc\`es au disque. L'utilisation de \TT{RDD}s permet aux applications de mettre en cache des donn\'ees \`a travers diff\'erentes \'etapes de traitement, ce qui acc\'el\`ere consid\'erablement la r\'eutilisation pour les traitements futurs. De plus, les \TT{RDD}s m\'emorisent les op\'erations utilis\'ees pour les construire et utilisent un m\'ecanisme de \emph{checkpoint}. Lorsqu'une panne survient, les \TT{RDD}s requis peuvent \^etre reconstruits, et ce sans devoir tout refaire les calculs.

Les \TT{RDD}s sont conçus pour \^etre partitionn\'es, donc r\'epartis sur diff\'erentes machines. Chaque partition contient des enregistrements qui peuvent \^etre cr\'e\'es par des op\'erations de transformations. Les transformations incluent notamment les opérations \TT{map}, \TT{filter}, \TT{groupBy} et \TT{join}.



%Les \TT{RDD}s peuvent \^etre cr\'e\'es via d'autres \TT{RDD}s existants. Ce m\'ecanisme permet la reconstruction des partitions perdues, car chaque \TT{RDD} dispose d'informations suffisantes sur la reconstruction \`a partir d'autres \TT{RDD}s. Lorsqu'il y a une demande de mise en cache d'un \TT{RDD}, par d\'efaut \TT{Spark} stocke ces partitions en m\'emoire. Cependant, des partitions peuvent aussi \^etre stock\'ees sur disques, lorsque la m\'emoire est insuffisante.


\subsection{\emph{Discretized Streams}}

\TT{Spark} traite un flux incr\'emental de donn\'ees \`a l'aide du mod\`ele \emph{Discretized Streams} --- \TT{D-stream}s.   
%
Ce mod\`ele est une autre abstraction introduite en \TT{Spark}. 
% Il s'agit essentiellement d'un flux de RDD dont les \'el\'ements sont les donn\'ees re\c cues par flux en entr\'ee pour le traitement par lots.
% %
\TT{Spark} d\'ecompose un flux de donn\'ees en une s\'erie de lots, en fonction de courts intervalles de temps, lots appel\'es \emph{micro-batches}. Chaque \emph{micro-batch} stocke ses donn\'ees dans un \TT{RDD}. Ensuite, la \emph{micro-batch} est trait\'ee et ses r\'esultats sont stock\'es dans des \TT{RDD}s interm\'ediaires.


\subsection{Exemple~: \TT{wordCount}}


\begin{lstlisting}[
basicstyle=\footnotesize\tt,
label={wordCountSpark},
language=java,
caption={Un segment de code \TT{Spark/Java} pour compter le nombre d'occurrences de mots. Exemple provenant du site Web pour \TT{Apache Spark} (\url{https://spark.apache.org/examples.html}).},
frame=single,
escapechar=\!,
float]
JavaRDD<String> textFile = 
    sc
    .textFile("hdfs://...");

JavaPairRDD<String, Integer> counts = 
    textFile
    .flatMap( s -> Arrays.asList(s.split(" ")).iterator() )
    .mapToPair( word -> new Tuple2<>(word, 1) )
    .reduceByKey( (a, b) -> a + b );

counts
    .saveAsTextFile("hdfs://...");
\end{lstlisting}


Afin d'illustrer le mod\`ele de programmation avec les \TT{RDD}s de \TT{Spark}, le listing~\ref{wordCountSpark} montre le code source d'un segment de code de d\'ecompte des mots, code \'ecrit en \TT{Java}.%
%
\footnote{\url{https://spark.apache.org/examples.html}}
%
Plus pr\'ecis\'ement, ce segment de code compte le nombre d'occurrences des divers mots dans un fichier texte et est compos\'e de plusieurs op\'erations~: 
\begin{itemize}

\item \TT{textFile}, qui lit les lignes \`a partir d'un fichier. Le fichier est identifi\'e par le param\`etre fourni en argument \`a \TT{textFile}.

\item \TT{flatMap}, qui divise chaque ligne en mots, qui sont ensuite transmis en aval sous forme d'\'el\'ements de donn\'ees individuels.

\item \TT{mapToPair}, qui cr\'ee une paire (de type \TT{Tuple2}) avec une cl\'e indiquant le mot et une valeur associ\'ee \'egale \`a 1.

\item \TT{reduceByKey}, qui regroupe les mots similaires ensemble et compte le nombre d'occurrences de chaque mot.


\end{itemize}



\section{\TT{Stream}s de \TT{Java} 8}
\label{java8.sect}

La version 8 de \TT{Java}, qui a introduit les \TT{Stream}s, a chang\'e la façon dont les d\'eveloppeurs peuvent traiter, tant de fa\c{c}on s\'equentielle que parall\`ele, les collections de donn\'ees. La manipulation de collections de donn\'ees \`a l'aide de \TT{Stream}s ressemble \`a un langage de requ\^etes de base de donn\'ees. Au lieu de parcourir explicitement les donn\'ees \`a l'aide de boucles (\TT{for}), un d\'eveloppeur sp\'ecifie simplement une suite d'op\'erations \emph{fonctionnelles} \`a effectuer sur les \'el\'ements d'une collection. \cite{urma2014java} fournissent une description d\'etaill\'ee des nouveaux concepts introduits dans \TT{Java~8}. Les \TT{Stream}s et les \emph{expressions lambdas} sont les fonctionnalit\'es les plus remarquables ajout\'ees dans l'API \citep{javaStreamAPI}. Ils sont con\c{c}us pour traiter les collections de donn\'ees de mani\`ere simple et efficace. Les sous-sections qui suivent d\'ecrivent quelques-uns des concepts de \TT{Java~8}.


\subsection{Expressions lambda}



\begin{lstlisting}[
label={exLambda},
language=java,
gobble=4,
caption={[Un exemple d'une expression lambda qui re\c{c}oit deux valeurs de type entier en argument.]Un exemple d'une expression lambda qui re\c{c}oit deux valeurs de type entier en argument, affect\'ee \`a la variable \TT{a}. Un appel est ensuite effectu\'e et le r\'esultat est affect\'e \`a la variable \TT{result}.},
frame=single,
float]
    interface Addable { int add (int x, int y); }
    
    int x = 3;
    int y = 2;
    
    // Affectation de l'expression lambda a une variable.
    Addable a = (int w, int z) -> { return w + z; };

    // Appel de l'expression lambda.
    int result = a.add(x, y);    
\end{lstlisting}



Une \emph{expression lambda} ---  appel\'ee aussi \emph{fonction anonyme} --- est un bloc de code avec des param\`etres qui peut \^etre d\'efini, comme n'importe quelle valeur, puis qui peut \^etre ex\'ecut\'e ult\'erieurement. Par exemple, la fonction anonyme du listing~\ref{exLambda}, qui re\c{c}oit deux valeurs de type entier en argument et renvoie leur somme, est affect\'ee \`a la variable \TT{a}. Un appel \`a la m\'ethode \TT{add} --- de l'interface \TT{Addable} --- est ensuite effectu\'e avec des arguments effectifs (\TT{x} et \TT{y}).


\begin{lstlisting}[
label={lambdaAsFonctionalInterface},
language=java,
gobble=4,
caption={Un exemple de remplacement d'une classe anonyme par une expression lambda.},
frame=single,
float]
    // Specification d'un thread avec une classe interne anonyme.
	Thread th = new Thread( new Runnable() {
		public void run() {
          ... // Code a executer par le thread.
		}
	});

    // Specification d'un thread avec une expression lambda.
	Thread th = new Thread( () -> {
         ... // Code a executer par le thread.
	});
\end{lstlisting}


Le concept d'expression lambda n'est pas nouveau. Il est utilis\'e depuis longtemps dans les langages de programmation fonctionnelle tels que \TT{Lisp}~\citep{Steele84} ou \TT{Haskell}~\citep{HudakWad90,hutton2016programming}.
%
Les expressions lambda rendent le code plus concis et, dans le cas de \TT{Java}, l'\'etendent avec des concepts de langages de programmation fonctionnelle. 

Plus sp\'ecifiquement, en \TT{Java}, ce concept est li\'e \`a celui d'interface fonctionnelle. Une expression lambda peut \^etre sp\'ecifi\'ee \`a la place d'une valeur dont le type est une interface fonctionnelle. Par exemple, le listing~\ref{lambdaAsFonctionalInterface} montre un exemple o\`u un \TT{Thread th}, d\'eclar\'e en utilisant la syntaxe de classe anonyme, peut \^etre \'ecrit plus facilement avec une expression lambda.

Dans une expression lambda, lors de la compilation, les types des arguments peuvent \^etre automatiquement d\'etermin\'es par le compilateur. Cette fonctionnalit\'e permet de passer des m\'ethodes comme arguments plut\^ot que de construire un objet d'une classe sp\'ecifique. Ceci permet \`a un programmeur de construire facilement des pipelines d'op\'erations fonctionnelles.


\subsection{It\'erations}


\begin{lstlisting}[
label={comparisonInternVsExtern},
language=java,
gobble=4,
caption={[Un exemple comparant it\'eration externe et interne.]Un exemple comparant une it\'eration externe et interne. Dans le cas de l'it\'eration externe, le d\'eveloppeur d\'efinit une boucle explicite pour traiter les divers \'el\'ements de la collection.  Le traitement appliqu\'e \`a chaque \'el\'ement consiste \`a convertir la cha\^ine en lettres majuscules si elle d\'ebute par la lettre <<\TT{J}>>. Le m\^eme traitement est appliqu\'e dans le cas de l'it\'eration interne. Par contre, dans ce cas, c'est le \TT{Stream} --- produit par l'appel <<\TT{myList.stream()}>> --- qui contr\^ole le processus d'it\'eration~; l'usager  indique simplement les diverses op\'erations \`a effectuer, en les chainant les unes \`a la suite des autres.},
frame=single,
float]
    List<String> myList =
            Arrays.asList("Tom", "John", "Harry", "Jonathan");

    // Iteration externe avec ajout explicite (style imperatif).
    List<String> resultExtern = new ArrayList<String>();
    for (String s: myList){
        if (s.startsWith("J")) // Selection
           // Transformation et ajout dans le resultat.
           resultExtern.add(s.toUpperCase()); 
    }
        
    // Iteration interne avec pipeline d'operations (style fonctionnel).
    List<String> resultIntern = 
        myList
        .stream()
        .filter(s -> s.startsWith("J")) // Selection.
        .map(String::toUpperCase)       // Transformation.
        .collect(Collectors.toList());  // Collecte du resultat.
\end{lstlisting}


Une it\'eration est le processus qui consiste \`a traverser une collection d'\'el\'ements pour traiter chacun d'entre eux. Avec les \TT{Stream}s \TT{Java}, une it\'eration peut \^etre ex\'ecut\'ee de deux mani\`eres : par une it\'eration \emph{externe} ou \emph{interne}. 

Une it\'eration est dite \emph{externe} lorsque le d\'eveloppeur contr\^ole la travers\'ee des \'el\'ements.  L'acc\`es et l'op\'eration sur chaque \'el\'ement de la collection sont d\'efinis par l'utilisateur. Par contre, une it\'eration est dite \emph{interne} lorsque la collection contr\^ole elle-m\^eme tous les d\'etails du processus d'it\'eration. L'utilisateur fournit uniquement les op\'erations permettant de traiter les \'el\'ements, sans se soucier de la mani\`ere dont les \'el\'ements sont acc\'ed\'es et fournis. Le listing~\ref{comparisonInternVsExtern} montre un exemple d’une comparaison entre une itération externe et interne. 

L'approche interne est attrayante pour les opportunit\'es qu'elle offre aux compilateurs, notamment l'optimisation de l'exécution et les m\'ecanismes de nettoyage n\'ecessaires en arri\`ere-plan. Un autre avantage des it\'erations internes est l'efficacit\'e, le traitement pouvant \^etre r\'eparti entre les cœurs de la machine pour une ex\'ecution parall\`ele.


\begin{figure}
\centering
     \includegraphics[width=1.0\textwidth]{Figures/ComparisonSequentialVsParallel.pdf}
      \caption[Une comparaison entre traitement s\'equentiel et parall\`ele.]{Une comparaison entre traitement s\'equentiel et parall\`ele. Les six \'el\'ements du flux (\TT{E1}, \ldots,  \TT{E6}) sont r\'epartis dans quatre sous-flux. Chaque sous-flux est trait\'e par l'un de quatre cœurs disponibles. Les r\'esultats sont combin\'es apr\`es le traitement.}
       \label{ComparisonSequentialVsParallel.fig}
\end{figure}


Lorsqu'un flux s'ex\'ecute en parall\`ele, \TT{Java} partitionne le flux en plusieurs sous-flux. Les op\'erations parcourent et traitent ces sous-flux en parall\`ele, puis combinent les r\'esultats. La figure~\ref{ComparisonSequentialVsParallel.fig} illustre la comparaison entre  un traitement s\'equentiel et un traitement parall\`ele, dans cet exemple avec quatre c\oe{}urs. Les \'el\'ements du flux sont partitionn\'es en sous-flux et chaque sous-flux r\'esultant est trait\'e par l'un de quatre cœurs disponibles.  



\subsection{Flux}


\begin{lstlisting}[
label={findFirst},
language=java,
gobble=2,
caption={Un exemple d'optimisation du traitement d'un flux en utilisant la technique d'\'evaluation court-circuit\'ee.},
frame=single,
float]
	List<Employee> employees;
	Optional<Employee> employee = employees.findFirst();
\end{lstlisting}


Un flux est d\'efini comme une s\'equence immuable d'\'el\'ements fournissant une vari\'et\'e d'op\'erations et de m\'ethodes permettant de traiter une collection de donn\'ees. Le flux prend en charge les op\'erations d'agr\'egation \citep{javaStreamAggregate} s\'equentielles et parall\`eles sans se soucier de la mani\`ere dont les \'el\'ements sont stock\'es ou accessibles. Pour effectuer un traitement, les op\'erations de flux sont compos\'ees dans un \TT{pipeline}. Un \TT{pipeline} est compos\'e d'une source, de z\'ero ou plusieurs op\'erations interm\'ediaires et d'une op\'eration terminale. Une source peut \^etre constitu\'ee d'une collection ou de tout objet impl\'ementant l'interface qui d\'efinit le m\'ecanisme permettant d'extraire les donn\'ees de la source. 
Les op\'erations sur les flux adoptent un m\'ecanisme d'\'evaluation paresseuse. L'\'evaluation paresseuse est une m\'ethode d'optimisation du traitement qui retarde l'\'etape du calcul jusqu'\`a ce que le r\'esultat soit nécessaire. En \TT{Java}, le traitement sur les \'el\'ements du flux est r\'ealis\'e seulement \`a l'activation de l'op\'eration finale et les \'el\'ements source ne sont consomm\'es qu'au besoin. Cela permet au compilateur d'optimiser le traitement des donn\'ees dans le \TT{pipeline}.
Une autre technique d'optimisation utilis\'ee par \TT{Java} est l'\'evaluation court-circuit\'ee (\emph{short-circuiting} en anglais). Dans un flux, une telle \'evaluation a pour effet que seuls les \'el\'ements n\'ecessaires sont consomm\'es.%
%
\footnote{L'\'evaluation court-circuit\'ee peut aussi \^etre vue comme une forme d'\'evaluation paresseuse, bien que la documentation \TT{Java} distingue ces deux formes d'optimisation.}
%
Par exemple, dans le listing~\ref{findFirst}, l'opérateur \TT{findFirst} retourne le premier employ\'e trouv\'e dans une liste d'employ\'es~; les \'el\'ements restants du flux sont ignor\'es.


L'un des principaux avantages des flux est qu'ils peuvent \^etre \'evalu\'es soit de fa\c{c}on s\'equentielle, soit en parall\`ele. L'\'evaluation s\'equentielle est r\'ealis\'ee en ex\'ecutant toutes les op\'erations en \TT{pipeline} sur chaque \'el\'ement du flux. Lorsqu'un flux est \'evalu\'e en parall\`ele, il utilise un type sp\'ecial d'it\'erateur appel\'e \TT{Spliterator}. Ce dernier partitionne le flux de mani\`ere r\'ecursive en se divisant lui-m\^eme pour cr\'eer des flux enfants. Ce m\'ecanisme permet aux \emph{threads} de traverser plusieurs flux en parall\`ele. Les \emph{threads} sont g\'er\'es par un groupe de \emph{threads} de type \TT{fork/join}.


\subsection{\emph{Threads} de type \TT{fork/join}}
\label{forkjoin.sect}

Introduit en \TT{Java~7}, le \emph{framework} \TT{fork/join} permet aux d\'eveloppeurs de sp\'ecifier des t\^aches pouvant \^etre subdivis\'ees et ex\'ecut\'ees en parall\`ele sur des machines multicœurs. Il est bas\'e sur deux op\'erations : \TT{fork} et \TT{join}. L'op\'eration \TT{fork} a pour r\^ole de diviser une t\^ache en plus petites sous-t\^aches ind\'ependantes, et ce  r\'ecursivement jusqu'\`a ce qu'elles soient assez simples pour \^etre ex\'ecut\'ees de mani\`ere ind\'ependante et asynchrone. L'op\'eration \TT{join} a pour r\^ole de fusionner les r\'esultats de toutes les sous-t\^aches de mani\`ere r\'ecursive en un seul r\'esultat.
Les sous-t\^aches obtenues par l'op\'eration \TT{fork} sont soumises \`a un \TT{ForkJoinPool}. Ce dernier est composé d'un ensemble de travailleurs. Le nombre de travailleurs dans un \TT{ForkJoinPool} est g\'en\'eralement limit\'e par le nombre de cœurs de la machine. Chaque travailleur peut ex\'ecuter une t\^ache \`a la fois. Les t\^aches en attente d'ex\'ecution sont stock\'ees dans une file appartenant \`a un travailleur. Une t\^ache en cours d'ex\'ecution peut g\'en\'erer de nouvelles t\^aches, qui sont ensuite mises en file  pour une ex\'ecution ult\'erieure. Lorsqu'un travailleur a termin\'e l'ex\'ecution d'une t\^ache et qu'il n'a plus aucune t\^ache dans sa propre file, il essaie de prendre une t\^ache d'un file d'un autre travailleur \`a l'aide d'un algorithme de vol de travail (\emph{work stealing algorithm}~\citep{FrigoLeiRan98}). Cet algorithme permet un \'equilibrage efficace de la charge de travail entre les divers travailleurs.


\subsection{Exemple~: \TT{wordCount}}


\begin{lstlisting}[
basicstyle=\footnotesize\tt,
label={wordCountJava},
language=java,
caption={Un pipeline \TT{Java} pour compter le nombre d'occurrences de mots.},
frame=single,
escapechar=\!,
float]
public static void main(String[] args) throws IOException {
  // Le texte a analyser, sous forme d'une chaine.
  String text = "Lorem ipsum dolor sit amet, consectetur \n" +
                " adipiscing elit. Lorem ipsum dolor sit amet, consectetur \n" +
                " adipiscing elit. Lorem ipsum dolor sit amet.";

  // Le texte a analyser decompose en une liste de lignes.
  ArrayList<String> lines = 
	new ArrayList<String>(Arrays.asList(text.split("\\n")));

  // Le pipeline qui traite la liste de lignes.	
  List<Map.Entry<String,Integer>> wordsCount = 
    lines
    .stream()
    .parallel()
    .flatMap(line->Arrays.stream(line.trim().split(" ")))
    .map(word->word.replaceAll("[^a-zA-Z]", "").toLowerCase())
    .filter(word->word.length() > 0)
    .map(word->new SimpleEntry<>(word, 1))
    .collect(toMap(e->e.getKey(), e->e.getValue(), (v1,v2)->v1+v2))
    .entrySet()
    .stream()
    .collect(Collectors.toList());   	
  
  wordsCount.forEach( x -> System.out.println("'" + x.getKey() + 
                                              "' => " + x.getValue()) );
}
!\vspace{-1cm}!
!\hrule!
!\underline{R\'esultat de l'ex\'ecution:}!
  'dolor' => 3
  'lorem' => 3
  'amet' => 3
  'adipiscing' => 2
  'ipsum' => 3
  'elit' => 2
  'consectetur' => 2
  'sit' => 3
\end{lstlisting}


Afin d'illustrer le mod\`ele de programmation avec les \TT{Stream}s de \TT{Java~8}, le listing~\ref{wordCountJava} montre le code source d'un segment de code \TT{Java} de d\'ecompte de mots. Plus pr\'ecis\'ement, ce segment de code compte le nombre d'occurrences des mots dans un chaine et est compos\'e de plusieurs op\'erations \emph{cha\^in\'ees} les unes \`a la suite des autres :

\begin{itemize}
	\item \TT{lines}, qui renvoie un flux s\'equentiel de lignes \`a partir du fichier. Le fichier est rep\'er\'e par le param\`etre \TT{inputFile} fourni en argument.


	\item \TT{parallel}, qui marque le flux en tant que flux parall\`ele. Cette op\'eration permet ainsi de partitionner et d'ex\'ecuter le \TT{pipeline} en parall\`ele.

	\item \TT{flatMap}, qui divise chaque ligne en mots qui sont ensuite transmis en aval sous forme d'\'el\'ements de donn\'ees individuels.
	
	\item \TT{map}, qui supprime tous les caract\`eres qui ne sont pas des lettres puis transforme les lettres majuscules du mot en minuscules.
	
	\item \TT{filter},  s\'electionne dans le flux seulement les mots qui ne sont pas vides.
	
	\item \TT{map}, qui cr\'ee une paire (de type \TT{Entry}) avec une cl\'e repr\'esent\'ee par le mot et une valeur associ\'ee \'egale \`a 1.
	
	\item \TT{collect},  collecte les \'el\'ements dans un \TT{Map} et additionne le nombre d'occurrences de chacun des mots \`a l'aide de l'expression lambda.
	
	\item \TT{entrySet},  renvoie un flux de type cl\'e--valeur. La cl\'e est le mot et la valeur est son nombre d'occurrences dans le fichier.

	\item \TT{stream}, cr\'ee un nouveau flux de donn\'ees \`a partir de l'ensemble de paires.
	
	\item Finalement \TT{collect}, qui combine tous les \'el\'ements dans une liste.
	
	
\end{itemize}


\section{\TT{FastFlow}}
\label{fastflow.sect}

\TT{FastFlow} est une biblioth\`eque \TT{C++} qui, \`a la base, offre un ensemble de m\'ecanismes de bas niveau pour traiter les flux de donn\'ees et s'ex\'ecutant sur des machines multicœurs avec m\'emoire partag\'ee. La facilit\'e de d\'eveloppement avec \TT{FastFlow} est rendue possible en utilisant un ensemble de \emph{squelettes algorithmiques} offerts par la biblioth\`eque~\citep{AldinucciEtAl14}. Son efficacit\'e provient principalement de la mise en œuvre optimis\'ee de m\'ecanismes de communication de bas niveau et de sa conception en couches. Les squelettes algorithmiques offerts par \TT{FastFlow} peuvent \^etre utilis\'es pour exprimer les mod\`eles les plus courants de parall\'elisme. Ces squelettes algorithmiques peuvent \^etre imbriqu\'es pour cr\'eer des mod\`eles hi\'erarchiques de parall\'elisme plus complexes.

\TT{FastFlow} a \'et\'e conçue selon plusieurs principes: conception en couches, efficacit\'e des communications et synchronisation, et support pour le parall\'elisme de flux.

\subsection{Conception en couches}

\begin{figure}
\centering
     \includegraphics[width=1.0\textwidth]{Figures/FastFlowLayers.jpg}
      \caption[Les couches de \TT{FastFlow}.]{Les couches de \TT{FastFlow} --- figure tir\'ee de~\citep{Torquati15}.}
       \label{FastFlowLayers.fig}
\end{figure}


\TT{FastFlow} a \'et\'e conçue sous la forme d'une pile de couches pour permettre d'impl\'ementer des m\'ecanismes d'abstraction et d'optimisation \`a plusieurs niveaux. La figure~\ref{FastFlowLayers.fig} montre les trois principales couches: \emph{High-level patterns}, \emph{Core patterns} et \emph{Building blocks}. 

Le niveau le plus bas de la pile, \emph{Building blocks}, g\`ere les communications asynchrones entre les canaux de communication et g\`ere le cycle de vie des flux. Plus pr\'ecis\'ement, cette couche offre des services pour les couches sup\'erieures. Elle g\`ere les queues, les processeurs et les fils d'ex\'ecutions (\emph{threads}).

Au-dessus de la couche \emph{Building blocks} se trouve la couche \emph{Core patterns}, qui fournit des squelettes (gabarits) pour mod\'eliser diff\'erentes formes de parall\'elisme de flux. Les trois mod\`eles fournis dans cette couche sont \emph{task-farm}, \emph{pipeline} et \emph{feedback}, qui permettent de construire des flux parall\`eles vari\'es. 

Au sommet de la pile se trouve la couche \emph{High-level patterns}, qui permet d'exprimer le parall\'elisme de plus haut niveau. Elle fournit plusieurs m\'ethodes qui couvrent les paradigmes de programmation parall\`eles les plus courants : parall\'elisme de flux, parall\'elisme de donn\'ees et  parall\'elisme de t\^aches. 

\subsection{Efficacit\'e}

L'id\'ee de \TT{FastFlow} est de fournir au programmeur des files (\emph{queues}) \emph{MP (Multiple Producer)} et des files \emph{MC (Multiple Consumer)} sans verrouillage, et ce afin de supporter des acc\`es rapides aux flux de donn\'ees. G\'en\'eralement, dans les applications de flux de donn\'ees, les canaux de communication sont impl\'ementés via des files de type \emph{MPMC (Multiple Producer/Multiple Consumer)}. Dans ce modèle, les acteurs se synchronisent simultanément pour acc\'eder aux donn\'ees. Ces synchronisations sont habituellement support\'ees par une ou plusieurs op\'erations atomiques --- par exemple, \TT{Compare-And-Swap} --- qui se comportent comme des barri\`eres de m\'emoire, ce qui augmente le co\^ut des synchronisations. Afin d'\'eviter les barri\`eres de m\'emoire, \TT{FastFlow} b\^atit les files \emph{MPMC} en assemblant des files, sans barri\`ere de m\'emoire, de type \emph{SPSC (Single Producer/Single Consumer)}. Dans ce mod\`ele, des files d’ex\'ecution regroupent ou \'emettent les donn\'ees des files d'entr\'ee vers les files de sortie. Selon son r\^ole, une file d'ex\'ecution peut \^etre un \TT{Emitter} ou un \TT{Collector}. Alors que l'\TT{Emitter} lit les donn\'ees, le \TT{Collector} \'ecrit sur une ou plusieurs files de types \emph{SPSC}. Contrairement aux op\'erations atomiques, ce m\'ecanisme n\'ecessite seulement des copies de m\'emoire --- la performance offerte par cette solution d\'ecoule de la vitesse sup\'erieure de la copie par rapport \`a la barri\`ere de m\'emoire.


\subsection{Parall\'elisme de flux}

Dans \TT{FastFlow}, le parall\'elisme de flux est repr\'esent\'e par un flux de donn\'ees comportant une s\'erie d'\'etapes, s\'equentielles ou parall\`eles, appel\'ees \emph{stages}. Chaque \emph{stage} lit les donn\'ees \`a partir du flux d'entr\'ee, effectue des calculs et traitements, puis \'ecrit le r\'esultat sur le flux de sortie. Le calcul repr\'esente une s\'equence de transformations sur les donn\'ees. Le parall\'elisme est obtenu en ex\'ecutant chaque \emph{stage} simultan\'ement sur des \'el\'ements ind\'ependants ou sur des sous-s\'equences d'\'el\'ements. 

Dans \TT{FastFlow}, le parall\'elisme peut \^etre obtenu en exploitant directement les mod\`eles parall\`eles disponibles dans la couche \emph{Building blocks}. En particulier, cela peut \^etre r\'ealis\'e des deux fa\c{c}ons suivantes :

\begin{itemize}
\item en d\'efinissant des activit\'es concurrentes s\'equentielles en sous-classant la classe \TT{ff\_node}~;
 
\item en construisant des mod\`eles parall\`eles complexes en composant de mani\`ere hi\'erarchique des activit\'es concurrentes s\'equentielles, soit avec des \emph{pipelines} --- \TT{ff\_pipeline} --- ou des \emph{farms} --- \TT{ff\_farm}.
\end{itemize}

\subsubsection*{La classe \TT{ff\_node}}

Dans \TT{FastFlow}, \TT{ff\_node} est la classe de base pour un noeud de traitement. Elle fournit les m\'ecanismes appropri\'es pour d\'efinir des activit\'es s\'equentielles pour le traitement de données apparaissant sur un canal d'entr\'ee et fournissant les r\'esultats correspondants sur un canal de sortie. 

\goodbreak
\begin{samepage}
La classe \TT{ff\_node} d\'efinit plusieurs m\'ethodes, les trois plus importantes \'etant les suivantes :
\begin{lstlisting}[language=c++]
    virtual void* svc(void* task) = 0
    virtual int svc_init() { return 0; } 
    virtual void svc_end() {} 
\end{lstlisting}
\end{samepage}

La premi\`ere m\'ethode, \TT{svc} (mn\'emonique <<service>>), est la plus importante car c'est celle qui d\'efinit le comportement du nœud lors du traitement des \'el\'ements du flux d'entr\'ee. Quant aux deux autres m\'ethodes, elles sont appel\'ees lorsque le traitement repr\'esent\'e par le nœud est d\'emarr\'e \TT{(svc\_init)} et juste avant qu'il soit termin\'e \TT{(svc\_end)}. Ces trois m\'ethodes virtuelles peuvent \^etre red\'efinies dans des sous-classes \TT{ff\_node} sp\'ecifi\'ees par le programmeur afin d'impl\'ementer le traitement, l'initialisation ou la finalisation du code.


\subsubsection*{La classe \TT{ff\_pipeline}}

Un \emph{pipeline} est utilis\'e pour mod\'eliser les traitements exprim\'es par des \emph{stages}. Il est repr\'esent\'e par la classe \TT{ff\_pipeline}. Un {pipeline} peut comporter plusieurs \emph{stages}, peut \^etre construit comme un pipeline \`a \emph{n} \emph{stages}, ou encore comme un {pipeline} de {pipelines}. Un \emph{stage} peut \^etre de type \TT{ff\_node} ou \TT{ff\_farm}.


\goodbreak

\subsubsection*{La classe \TT{ff\_farm}}
\label{farm.sect}

\begin{figure}	%[htbp]
     \centering
     \includegraphics[width=1.0\textwidth]{Figures/FastFlowFarm.pdf}
      \caption[Les trois parties d'un \emph{farm} de \TT{FastFlow}.]{Un \emph{farm} de \TT{FastFlow} est compos\'e de trois parties~:  l'\TT{Emitter (E)}, le \emph{pool} de \TT{workers} (W1\ldots\ Wn) et le \TT{Collector (C)}. Les canaux de communication sont impl\'ement\'es en assemblant des files de types \emph{Simple Producer/Simple Consumer (SPSC)} --- figure tir\'ee de~\citep{aldinucci2010efficient}.}
       \label{FastFlowFarm.fig}
\end{figure}

Un \emph{farm} est bas\'e sur la r\'eplication d'une fonction. Dans \TT{FastFlow}, un \emph{farm} est repr\'esent\'e par un objet de la classe \TT{ff\_farm}. Comme le montre la figure~\ref{FastFlowFarm.fig}, un \emph{farm} est compos\'e de trois parties distinctes: un \TT{Emitter}, un  \emph{pool} de \TT{workers} et un \TT{Collector}. L'\TT{Emitter} est responsable de la r\'epartition des \'el\'ements du flux au \emph{pool} de \TT{workers}, lesquels traitent et produisent les donn\'ees de sortie; l'\TT{Emitter} distribue les \'el\'ements d'entr\'ee aux travailleurs selon une certaine politique d'ordonnancement afin d'\'equilibrer la charge des travailleurs. Les r\'esultats sont ensuite rassembl\'es par le \TT{Collector} dans un seul flux de sortie. Les communications entre \TT{Emitter} et \TT{Collector} se font via des canaux de communication sans barri\`eres de m\'emoire, tel que d\'ecrit pr\'ec\'edemment.


\subsection{Exemple~: \TT{WordCount}}


\begin{lstlisting}[language=c++, 
caption={Le code source \TT{FastFlow} d'une application pour compter le nombre d'occurrences de mots.},
label={wordcountFastFlow},
frame=single,
float,
numbers=left
]
 std::string DEFAULT_INPUT_FILE = "Words.txt";
 
 typedef std::vector<std::string> Words;
 
 struct linesFromFileStage: ff_node {
    std::string const &path;
    linesFromFileStage(std::string const &path): path(path){}
 
    void* svc(void* task) {
       std::ifstream file(path);
       std::string* line = new std::string;
       while (std::getline(file, *line)) {
           ff_send_out(line);
           line = new std::string;
       }
       return EOS;
    }
 };
 
 struct splitInWordsStage: ff_node {
    std::string delimiter = " ";
    void* svc(void* task) {
       std::string line = *((std::string*)task);
       Words* words = new Words();
       size_t start = 0, end = 0;
       do {
           end = line.find(delimiter, start);
           size_t len = end - start;
           words->push_back( line.substr(start, len) );
           start += len + delimiter.length();
       } while (end != std::string::npos);

       return words;
    }
 };
\end{lstlisting}
 
\begin{lstlisting}[language=c++, frame=single,float,numbers=left,firstnumber=35]
 struct flatStage: ff_node {
    std::string delimiter = " ";
    void* svc(void* task) {
        for (auto &elem: *(Words*)task) {
            ff_send_out(&elem);
        }
        return GO_ON;
    }
 };
 
 struct groupByKeyStage: ff_node {
    typedef std::unordered_map<std::string, int> CONTAINER;
    CONTAINER &container;
    groupByKeyStage(CONTAINER &container): container(container){}
    void* svc(void* task) {
       container[*((std::string*)task)] += 1;
       return GO_ON;
    }
 };
\end{lstlisting}
 
\begin{lstlisting}[language=c++, frame=single, float, numbers=left,firstnumber=54]
 int main(int argc, char *argv[]) {
     std::unordered_map<std::string, int> result;
     std::string inputFile = DEFAULT_INPUT_FILE;

     if (argc >= 2) { inputFile = argv[1]; } 

     linesFromFileStage linesFromFile(inputFile);
     splitInWordsStage splitInWords;
     flatStage flat;
     groupByKeyStage groupByKey(result);

     ff_pipeline ffp;
     ffp.add_stage(&linesFromFile);
     ffp.add_stage(&splitInWords);
     ffp.add_stage(&flat);
     ffp.add_stage(&groupByKey);

     if (ffp.run_and_wait_end() < 0) error("running pipe");
     return 0;
 }
\end{lstlisting}

Cette section pr\'esente un exemple d'un programme r\'ealis\'e en \TT{FastFlow}. Illustr\'e dans le listing~\ref{wordcountFastFlow}, ce programme compte le nombre d'occurrences des divers mots dans un fichier texte. 

Un {pipeline} de \TT{n} \TT{stages} distincts est cr\'e\'e en instanciant les \TT{n} diff\'erents \TT{stages}; ensuite leurs r\'ef\'erences sont transmises dans le bon ordre au {pipeline}. Dans l'exemple du listing~\ref{wordcountFastFlow}, les \TT{stages} sont repr\'esent\'es par les op\'erations du programme de d\'ecompte du nombre de mots --- lignes 66 \`a 69.  Les quatre op\'erations r\'ealisent les fonctions suivantes :

\begin{itemize}
    \item \TT{linesFromFile}, qui renvoie un flux s\'equentiel de lignes \`a partir du fichier. Le fichier est identifi\'e par le param\`etre \TT{inputFile} fourni en argument.

    \item \TT{splitInWords}, qui divise chaque ligne en mots qui sont ensuite transmis en aval sous forme d'une collection de mots.
    
    \item \TT{flat}, qui décompose la collection en mots individuels, lesquels sont ensuite transmis dans le flux en tant qu'éléments individuels de données.
    
    \item \TT{groupByKey}, qui regroupe les mots similaires ensemble et ensuite compte le nombre d'occurrences de chaque mot.
    
\end{itemize}

\section{Autres biblioth\`eques C++}    
\subsection{RaftLib} 
\TT{RaftLib}~\citep{beard2017raftlib} est une plus r\'ecente biblioth\`eque \emph{C++} con\c{c}ue pour traiter des flux de donn\'ees. \'Ecrit \`a l'aide de templates, \TT{RaftLib} vise \`a parall\'eliser de mani\`ere transparente une application, tout en minimisant la refactorisation du code h\'erit\'e. Comme \TT{FastFlow}, il fournit aux programmeurs un ensemble de m\'ecanismes de bas niveau pour traiter les flux de donn\'ees. Les programmes r\'esultants sont capables de fonctionner sur des plates-formes multi-cœurs avec m\'emoires partag\'ees ainsi que sur des plates-formes avec m\'emoires distribu\'ees.


%\gt{À moins que tu en dises beaucoup plus, pas besoin il me semble d'avoir des sous-sections.}

%\subsubsection*{Conception}
\TT{RaftLib} construit le flux de traitement sous forme d'un graphe en connectant des nœuds à des ports. Les nœuds, appel\'es noyaux de calcul, sont des classes \emph{C++} qui \'etendent la classe \TT{raft::kernel}. Dans le constructeur de cette classe sont d\'efinis les ports. Les ports sont d'entrée ou sortie pour chaque noyau de calcul. Chacun de ces noyaux impl\'emente une m\'ethode d'ex\'ecution o\`u des op\'erations de traitement sont effectu\'ees. Le graphe est construit dans la m\'ethode \TT{main} o\`u les noyaux d\'eclar\'es sont li\'es en connectant des ports \`a l'aide d'op\'erateurs de liaison. 

La communication entre les noyaux s'effectue via des files de type \TT{FIFO} (\emph{First-In, First-Out}), et les donn\'ees envoy\'ees dans le flux sont assurées d'arriver dans l'ordre. Les donn\'ees entrent dans le nœud via le port d'entr\'ee d\'efinie dans chaque classe de noyau de calcul. Une fois les donn\'ees trait\'ees, elles sont envoy\'ees \`a la sortie via le port de sortie d\'efinie dans la m\^eme classe.  Les files sont réalisées \`a l'aide de diff\'erents types de tampons tels que la m\'emoire partag\'ee ou la m\'emoire dynamique (\emph{heap memory}). L'\`etat du traitement est conserv\'e en interne par chaque noyau de calcul, mais il n'est pas conserv\'e entre les noyaux. Cela permet une parall\'elisation beaucoup plus simplifi\'ee.


%\subsubsection*{Acc\`es aux donn\'ees}
%
Dans \TT{RaftLib}, il existe plusieurs options pour \'echanger les donn\'ees entre des noyaux de calcul. Le processus comprend deux \'etapes: lire les donn\'ees \`a partir des ports d'entr\'ee et \'ecrire les donn\'ees sur les ports de sortie. Une fois les données envoy\'ees au port de sortie, elles sont disponibles pour le noyau en aval.

% \gt{Pas besoin de dire <<en anglais>>. Simplement mettre le terme en
% italiques entre parenthèses.}

% \gt{Attention: si tu utilises \TT{$\backslash$cite}, alors c'est que
% tu veux utiliser le nom de l'auteur comme sujet de la phrase. Sinon,
% tu dois utiliser \TT{$\backslash$citep}. Et il faut mettre un espace
% insécable <<\~{}>> juste avant.}

Il existe deux types de m\'ethodes d'envoi et de r\'eception des donn\'ees : les m\'ethodes sans copie (\emph{zero copy}) et les m\'ethodes avec copie~\citep{accessingDataInRaftLib}. \emph{Zero copy} signifie que les donn\'ees ne sont pas d\'eplac\'ees du noyau vers le contexte de l'application, ce qui \'elimine les copies inutiles des donn\'ees. Les m\'ethodes avec copie peuvent \^etre plus rapides pour les transferts de petite taille tels que les donn\'ees de type primitif.
%

% \gt{Petit rappel: on utilise $\backslash$emph pour les termes en
% anglais, mais on utilise $\backslash$texttt (ou $\backslash$TT) pour
% les noms qui représentent des identificateurs de code.}

\GT{Est-ce qu'il y avait des exemples dans l'article? Sans montrer ces
exemples, sur la base de leur lecture, pourrais-tu plutôt dire
quelques mots sur le style de programme que cela crée?  On doit, comme
en FastFlow, créer le graphe de facçon impérative, un noeud/une
connection à la fois? Ou c'est implicite comme en PpFf via chainage de
méthodes?  C'est plutôt sur cet aspect qu'il faudrait insister, si tu
peux.}

\IC{Je vais y réflechier. C'est un bon point. Ce sera peut-être une bonne idée de parler aussi de la différence de style entre PpFf et FastFlow. Je crois que l'un d'évaluateurs l'a méntionné dans ses commentaires.}


\subsection{StarPU} 

\begin{figure}
\centering
     \includegraphics[width=1.0\textwidth]{Figures/StarPUInternalStructure.png}
      \caption[La structure interne de \TT{StarPU}.]{ La structure interne de \TT{StarPU} --- figure tir\'ee de~\citep{starPuRuntime}.}
       \label{StarPUInternalStructure.fig}
\end{figure}


Un outre outil pour le traitement de flux de donn\'ees est \TT{StarPu}. \TT{StarPU}~\citep{starPuReferenceEnLigne} est un syst\`eme d'ex\'ecution visant \`a permettre aux programmeurs de g\'en\'erer des t\^aches parall\`eles sur des unit\'es de traitement comme \emph{CPU} et \emph{GPU}, tout en les d\'echargeant de la n\'ecessit\'e d'adapter sp\'ecialement leurs programmes \`a la machine cible.


Le mod\`ele de programmation \TT{StarPU} est un mod\`ele bas\'e sur les t\^aches. Les applications soumettent des t\^aches de calcul et \TT{StarPU} distribue ces t\^aches aux unit\'es de traitement disponibles. La figure~\ref{StarPUInternalStructure.fig} montre la structure interne de \TT{StarPU}. Le composant responsable de la distribution de t\^aches est << Scheduling engine >>. Les donn\'ees qu'une t\^ache manipule sont automatiquement transf\'er\'ees entre les unit\'es de traitement et la m\'emoire principale par le composant << High-level data management library >>. Ce composant vient \`a l'aide de d\'eveloppeurs en les lib\'erant de la charge des transferts de donn\'ees. De plus, il optimise le traitement en \'evitant les transferts inutiles. Les donn\'ees sont gard\'ees l\`a o\`u elles \'etaient n\'ecessaires la derni\`ere fois, m\^eme si elles ont \'et\'e modifi\'ees.

Afin de r\'eutiliser le code existent,  \TT{StarPU} introduise la notion de \emph{codelet}. Un \emph{codelet} d\'ecrit une unit\'e de calcul. Plut\^ot que de r\'e\'ecrire tout le code, les programmeurs peuvent encapsuler des fonctions existant dans des \emph{codelets}. En effet, dans  \TT{StarPU}, l'ex\'ecution d'une t\^ache consiste \`a appliquer un \emph{codelet} sur une structure de donn\'ees. Un \emph{codelet} peut \^etre impl\'ement\'e sur des architectures h\'et\'erog\`enes telles que \TT{CUDA} ou \TT{OpenCL}.  

Toutes les t\^aches dans \TT{StarPU} sont asynchrones. Autrement dit, soumettre une t\^ache \`a \TT{StarPU} est une op\'eration non bloquante. Comme tout autre syst\`eme, \TT{StarPU} introduit des co\^uts pour g\'erer les t\^aches. Ces co\^uts peuvent \^etre importants si la quantit\'e de travail \`a effectuer n'est pas assez grande. 


