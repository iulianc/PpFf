\begin{introduction}

Le traitement de flux de donn\'ees devient de plus en plus important en raison de la grande quantit\'e de donn\'ees continuellement g\'en\'er\'ees, provenant de diverses sources telles que des capteurs, des indicateurs boursiers, des dispositifs de r\'eseau, etc. Afin de traiter rapidement une grande quantit\'e de donn\'ees, notamment en exploitant les capacit\'es des processeurs multicœurs modernes, une application doit \^etre con\c cue en parall\`ele. La conception et la mise en œuvre d'applications parall\`eles efficientes pour traiter des flux de donn\'ees posent des d\'efis aux d\'eveloppeurs. Les co\^uts de communications~\citep{amarasinghe2011ascr}, les conditions de course (\emph{data race})~\citep{wu2015detecting}, les interblocages~\citep{haque2006concurrent} et les d\'es\'equilibres de charge de travail entre les fils d'ex\'ecution~\citep{amarasinghe2011ascr} sont quelques exemples de probl\`emes qui demandent des efforts suppl\'ementaires aux programmeurs. De plus, la complexit\'e du code peut diminuer la productivit\'e et, par cons\'equent, augmenter les co\^uts de d\'eveloppement. Ce m\'emoire vise \`a proposer une API (\emph{Application Programming Interface}), en C++, qui permet traiter de fa\c con simple et efficace les flux de donn\'ees en tentant de dissimuler cette complexit\'e.

\section*{D\'efinition du probl\`eme}

Une application qui traite un flux de données peut \^etre consid\'er\'ee comme un pipeline \`a travers lequel les donn\'ees du flux sont produites, trait\'ees et consomm\'ees en continu. Le parall\'elisme dans le traitement d'un tel flux consiste \`a traiter des \'el\'ements distinct du flux de fa\c{c}on concurrente --- \emph{parall\'elisme de flux} (\emph{flow parallelism} ou \emph{stream parallelism}) --- et \`a r\'epliquer un m\^eme op\'erateur sur des sous-groupes d'\'el\'ements du flux --- \emph{parall\'elisme de donn\'ees} (\emph{data parallelism}). La transformation, le tri ou la r\'eduction par un op\'erateur binaire sont des exemples d'op\'erations pour lesquelles du parall\'elisme de donn\'ees peut \^etre exploit\'e. 


\GT{C'est ici, il me semble, qu'il serait bien d'expliquer la
diff\'erence entre les applications qui traitent de grandes
quantit\'es de donn\'ees par lots (en \emph{batch}, \emph{offline}),
alors que d'autres les traitent en ligne (\emph{online}), de fa\c{c}on
incr\'ementale, au fur et \`a mesure o\`u ces donn\'ees deviennent
disponibles.}


Les applications parall\`eles sont g\'en\'eralement cod\'ees \`a l'aide de biblioth\`eques comme \TT{FastFlow}~\citep{AldinucciEtAl14} ou \TT{TBB}~\citep{Reinders07}. Bien que les mod\`eles offerts par ces outils aient pour but de simplifier le d\'eveloppement d'applications parall\`eles, ils n'offrent pas une abstraction de haut niveau et n\'ecessitent une r\'e\'ecriture de l'application sans possibilit\'e de r\'eutiliser le code s\'equentiel disponible.

\GT{Pour la derni\`ere phrase du paragraphe pr\'ec\'edent, je ne crois
pas que PpFF permette cela non plus.  Je crois que tu dois plut\^ot
insister sur le fait qu'on veut introduire un mod\`ele simple, o\`u le
programmeur cr\'ee un pipeline de transformations, et o\`u chaque
transformation est relativement simple --- donc, application du
principe <<diviser-pour-r\'egner>> mais de fa\c{c}on non r\'ecursive.}

R\'e\'ecrire une application est g\'en\'eralement co\^uteux en termes de temps de d\'eveloppement. Les approches visant \`a pallier ce d\'efaut sont souvent des outils de programmations parall\`eles d\'evelopp\'es pour introduire le parall\'elisme dans du code s\'equentiel existant. Des exemples sont \TT{OpenMP}~\citep{ChandraEtAl01} et \TT{OpenACC}~\citep{farber2016parallel} qui utilisent une approche bas\'ee sur l'ajout de directives --- des commentaires sp\'eciaux trait\'es par le compilateur---, et \TT{Cilk}~\citep{leiserson1998programming} qui est une extension simple du langage~\TT{C}. Malheureusement, ces outils ne sont pas bien adapt\'es au traitement de flux de donn\'ees.


Des outils qui supportent le traitement de flux de donn\'ees sont disponibles dans d'autres langages de programmation que \TT{C}/\TT{C++}. Les plus connus sont \TT{Spark}~\citep{frampton2015mastering} (Java, Scala et autres langages), les \TT{Stream}s de \TT{Java 8}~\citep{warburton2014java} et \TT{Flink}~\citep{flinkReferenceEnLigne} (Java et Scala). Un avantage principal de notre \TT{API} par rapport aux outils mentionn\'es est que le code (\'ecrit \`a l'aide de templates \TT{C++}) est compil\'e directement en code machine optimis\'ee m\^eme avant d'\^etre ex\'ecut\'e. 

\GT{Ci-haut, derni\`ere phrase: pas certain que ce soit le bon
avantage \`a mentionner.  Je crois qu'il faut \^etre clair \`a ce
point que l'API est tr\`es semblable (!) \`a celle des Streams de Java
8, mais en C++, et parfois/souvent plus simple \`a sp\'ecifier gr\^ace
aux templates.}

\section*{Objectifs}

\GT{Ci-bas: je vais relire. Pas certain que ce soit tr\`es clair. De
plus, tu utilises le terme <<mod\`ele algorithmique parall\`ele>> ou
<<mod\`ele parall\`ele>>... sauf que je ne sais pas trop bien \`a quoi
cela r\'ef\`ere. \'A quel terme anglais ce terme correspond-il? Quelle
est la r\'ef\'erence?}

Dans le contexte du langage de programmation \TT{C++}, il existe plusieurs biblioth\`eques qui offrent des mod\`eles algorithmiques parall\`eles pour le traitement de donn\'ees. Cependant, tous les mod\`eles entrent dans la cat\'egorie des mod\`eles parall\`eles de donn\'ees, comme la transformation et la r\'eduction. Ce m\'emoire a comme objectif d'enrichir cette collection avec de nouveaux mod\`eles parall\`eles avec une interface simple \`a utiliser. Ceci, associ\'e \`a de nouvelles fonctionnalit\'es telles que les expressions lambda~\citep{josuttis2012c++}, aide un programmeur \`a \'ecrire des op\'erations complexes pour un flux de donn\'ees. Cette nouvelle \TT{API} en \TT{C++}, appel\'ee \TT{PpFF},  est mise en \oe{}uvre avec la biblioth\`eque \TT{FastFlow}.

Les performances de \TT{PpFf} sont \'evalu\'ees en les comparant \`a celles des \TT{Stream}s de \TT{Java 8}. Comme nous le verrons, les r\'esultats indiquent que \TT{PpFf} peut en effet traiter de donn\'ees \`a haut d\'ebit. En plus de mesurer les performances de notre API, nous illustrerons \'egalement son expressivit\'e en impl\'ementant certains cas d'utilisation typiques rencontr\'es dans les applications de traitement de flux de donn\'ees.


\section*{Organisation du m\'emoire}

Les chapitres qui forment le c\oe{}ur du m\'emoire sont organis\'es
comme suit.


\GT{Il ne faut pas mettre de num\'eros ou noms explicites, sinon ils
ne seront plus corrects si tu les changes dans le corps du texte. De
plus, la conclusion n'est pas un chapitre num\'erot\'e.}

Le chapitre~\ref{outils_connus.chap} \nameref{outils_connus.chap} pr\'esente les outils existants portant sur le traitement des flux de donn\'ees.  Tout d'abord, il introduit les architectures utilis\'ees par divers outils, puis il pr\'esente les mod\`eles de programmations permettant d'exprimer les traitements de donn\'ees.

Le chapitre~\ref{description.chap} \nameref{description.chap} pr\'esente les m\'ethodes de notre \TT{API}. Un r\'esum\'e sous forme de tableau de toutes les m\'ethodes implément\'ees est pr\'esent\'e au d\'ebut du chapitre. Accompagn\'e de quelques exemples, le chapitre d\'ecrit aussi plus en d\'etail les m\'ethodes les plus importantes.

Le chapitre~\ref{implementation.chap} \nameref{implementation.chap} examine comment nous avons mis en œuvre notre \TT{API} en utilisant la biblioth\`eque bas niveau \TT{FastFlow}.

Finalement, le chapitre~\ref{experiences.chap} \nameref{experiences.chap} pr\'esente une \'evaluation des performances sur deux cas d'utilisation typiques.

\end{introduction}

